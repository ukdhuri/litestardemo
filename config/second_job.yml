---
# Sample YAML configuration

#any new varialbe will be added in this sample yaml
# Following varialbes are available to use directely without defining in file
# BDATE = this is business date, follows business schedule of working days
# CDATE = this is current datetime, follows system date. Thsi contains time, you can format it as per your requirement
# CTIME = same as abolve
# FILELINECNT = this is file line count, number of lines in data file
# PROCESSEDROWCNT = this is total number of record processed by bcp 
# ENV = this is environment, follows environment Value, comes from command line parameter

# OUPUTFILELINES = this is output file line count, number of lines in output file (this is of the file including header and trailer)
# INPUTFILELINES = this is input file line count, number of lines in input file (including header and trailer)
# INPUTFILEDATALINECOUNT = number of line in inputfile excluding header and trailer
# OUTPUTFILERDATALINECOUNT = number of line in output file excluding header and trailer, this number can differ from actual records in file if some data contains new line character
# INPUTDATAFRAMELENGHT = this is input data frame lenght, number of rows in input data frame
# OUTPUTDATAFRAMELENGHT = this is output data frame lenght, number of rows in output data frame

# AUTOPOPULATECOLNAMES = value of this will be replaced by column names of the file, this is used in headers_in_order. This variable should be sole vaiable in the string
# FILELINECOUNT =  this is file line count, number of lines in file
# DATALINECOUNT = = number of line in output file excluding header and trailer, this number can differ from actual records in file if some data contains new line character
# FILENAME = Inside input or output file configuration, this will be replaced by current file name after processing placeholder but without base path
# FULLFILENAME = Inside input or output file configuration, this will be replaced by current file name after processing placeholder with base path
# FILENAMEWE = Inside input or output file configuration, this will be replaced by current file name after processing placeholder but without base path and extension
# EXPECTEDFILELINECOUNT = this is expected final count, sum of datalinecount and all the headers and trailers
# EXPECTEDDATALINECOUNT = this is expected data line count, without header and trailer lines


#write a python funtion to generate sql query, you may use jinja2, in this i will pass source table anem and target table name both have 


# Define job name
name: first_job
group_seperator: "Â¶"
component_seperator: "â€¢"
ingnorable_character: 'ðŸ§¹'
child_access_symbol: 'â†’'

common_variables:
  test_varialbe: "test_value"
  test_varialbe1: "test_value2"


# Define job steps
job_steps:
  - stepy:
      type: table_pandas_loader
      load_type: truncate_and_load #other types are append_load and merge_load
      table:
        name: 'product2'
        database: remote
        validate: True #only supported in loader
      file:
        validate: True
        type: delimitedfile
        header_delimiter: ","
        header_quote_char: '"'  #optional default is empty
        delimiter: "|" #optional default is ','
        quote_char : 'ðŸ¤©'  #optional default is empty
        escape_char: '\'  #optional default is \, not used in bcp as of now, used for pandas
        path: "/home/deck/outbound"
        prefix: "FirstTestSamplex_Â¶BDATEâ€¢dateâ€¢YYYYMMDDÂ¶"
        ext: ".csv"
        headers_in_order:
          - "FILENAME=Â¶stepyâ†’fileâ†’FILENAMEâ€¢strâ€¢ <66Â¶ BATCH_DATE=Â¶BDATEâ€¢dateâ€¢YYYY-MM-DDÂ¶  CREATED_AT=ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹"
          - '"id","name","description","price"'
          - ''
        trailers_in_order:
          - 'RECORDCOUNT=Â¶stepyâ†’fileâ†’EXPECTEDDATALINECOUNTâ€¢intâ€¢08dÂ¶'
          - 'LINECOUNT=Â¶stepyâ†’fileâ†’FILELINECOUNTâ€¢intâ€¢08dÂ¶'
        dataframe_columns: 'id,name,description,price'
  - stepx:
      type: table_bcp_loader
      load_type: truncate_and_load #other types are append_load and merge_load
      table:
        name: 'Heavydev.dbo.product1'
        database: remote
        validate: True #only supported in loader
      file:
        validate: True
        type: delimitedfile
        header_delimiter: ","
        header_quote_char: '"'  #optional default is empty
        delimiter: "|" #optional default is ','
        quote_char : 'ðŸ¤©'  #optional default is empty
        escape_char: '\'  #optional default is \, not used in bcp as of now, used for pandas
        path: "/home/deck/outbound"
        prefix: "FirstTestSamplex_Â¶BDATEâ€¢dateâ€¢YYYYMMDDÂ¶"
        ext: ".csv"
        headers_in_order:
          - "FILENAME=Â¶stepxâ†’fileâ†’FILENAMEâ€¢strâ€¢ <66Â¶ BATCH_DATE=Â¶BDATEâ€¢dateâ€¢YYYY-MM-DDÂ¶  CREATED_AT=ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹"
          - '"id","name","description","price"'
          - ''
        trailers_in_order:
          - 'RECORDCOUNT=Â¶stepxâ†’fileâ†’EXPECTEDDATALINECOUNTâ€¢intâ€¢08dÂ¶'
          - 'LINECOUNT=Â¶stepxâ†’fileâ†’FILELINECOUNTâ€¢intâ€¢08dÂ¶'
  - step1:
      type: sql_bcp_extractor
      sqlfile:
        name: 'first_job_sql_query.sql'
        database: remote
      file:
        type: delimitedfile
        delimiter: "," #optional default is ','
        quote_char : 'ðŸ¤£'  #optional default is empty
        escape_char: '\'  #optional default is \, not used in bcp as of now, for future usey 
        path: "/home/deck/outbound"
        prefix: "FirstTestSample_Â¶BDATEâ€¢dateâ€¢YYYYMMDDÂ¶"
        ext: ".csv"
        headers_in_order:
          - "FILENAME=Â¶step1â†’fileâ†’FILENAMEâ€¢strâ€¢ <66Â¶ BATCH_DATE=Â¶BDATEâ€¢dateâ€¢YYYY-MM-DDÂ¶  CREATED_AT=Â¶CTIMEâ€¢dateâ€¢YYYY-MM-DDHH:mm:ssÂ¶"
          - 'AUTOPOPULATECOLNAMES'
          - 'xxxxxxxxxxxx'
        trailers_in_order:
          - 'RECORDCOUNT=Â¶step1â†’PROCESSEDROWCNTâ€¢intâ€¢08dÂ¶'
          - 'LINECOUNT=Â¶step1â†’fileâ†’EXPECTEDFILELINECOUNTâ€¢intâ€¢08dÂ¶'
  - step2:
      type: table_bcp_extractor
      table:
        name: 'Heavydev.dbo.product'
        database: remote
      file:
        validate: True
        type: delimitedfile
        header_delimiter: ","
        header_quote_char: '"'  #optional default is empty
        delimiter: "|" #optional default is ','
        quote_char : 'ðŸ¤©'  #optional default is empty
        escape_char: '\'  #optional default is \, not used in bcp as of now, used for pandas
        path: "/home/deck/outbound"
        prefix: "FirstTestSample2_Â¶BDATEâ€¢dateâ€¢YYYYMMDDÂ¶"
        ext: ".csv"
        headers_in_order:
          - "FILENAME=Â¶step2â†’fileâ†’FILENAMEâ€¢strâ€¢ <66Â¶ BATCH_DATE=Â¶BDATEâ€¢dateâ€¢YYYY-MM-DDÂ¶  CREATED_AT=Â¶CTIMEâ€¢dateâ€¢YYYY-MM-DDHH:mm:ssÂ¶"
          - 'AUTOPOPULATECOLNAMES'
          - 'yyyyyyyyyyyy'
        trailers_in_order:
          - 'RECORDCOUNT=Â¶step2â†’PROCESSEDROWCNTâ€¢intâ€¢08dÂ¶'
          - 'LINECOUNT=Â¶step2â†’fileâ†’EXPECTEDFILELINECOUNTâ€¢intâ€¢08dÂ¶'
  - step3:
      type: sql_panda_extractor
      sqlfile:
        name: 'first_job_sql_query.sql'
        database: remote
      file:
        validate: True
        type: delimitedfile
        delimiter: "|" #optional default is ','
        quote_char : 'ðŸ¤£'  #optional default is empty
        escape_char: '\'  #optional default is \, not used in bcp as of now, used for pandas
        path: "/home/deck/outbound"
        prefix: "FirstTestSample3_Â¶BDATEâ€¢dateâ€¢YYYYMMDDÂ¶"
        ext: ".csv"
        headers_in_order:
          - "FILENAME=Â¶step3â†’fileâ†’FILENAMEâ€¢strâ€¢ <66Â¶ BATCH_DATE=Â¶BDATEâ€¢dateâ€¢YYYY-MM-DDÂ¶  CREATED_AT=Â¶CTIMEâ€¢dateâ€¢YYYY-MM-DDHH:mm:ssÂ¶"
          - 'AUTOPOPULATECOLNAMES'
          - 'xxxxxxxxxxxx'
        trailers_in_order:
          - 'RECORDCOUNT=Â¶step3â†’PROCESSEDROWCNTâ€¢intâ€¢08dÂ¶'
          - 'LINECOUNT=Â¶step3â†’fileâ†’EXPECTEDFILELINECOUNTâ€¢intâ€¢08dÂ¶'
