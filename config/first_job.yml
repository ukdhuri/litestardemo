---
# Sample YAML configuration

#any new varialbe will be added in this sample yaml
# Following varialbes are available to use directely without defining in file
# BDATE = this is business date, follows business schedule of working days
# CDATE = this is current datetime, follows system date. Thsi contains time, you can format it as per your requirement
# CTIME = same as abolve
# FILELINECNT = this is file line count, number of lines in data file
# BCPPROCROWCNT = this is total number of record processed by bcp utility
# ENV = this is environment, follows environment Value, comes from command line parameter

# OUPUTFILELINES = this is output file line count, number of lines in output file (this is of the file including header and trailer)
# INPUTFILELINES = this is input file line count, number of lines in input file (including header and trailer)
# INPUTFILEDATALINECOUNT = number of line in inputfile excluding header and trailer
# OUTPUTFILERDATALINECOUNT = number of line in output file excluding header and trailer, this number can differ from actual records in file if some data contains new line character
# INPUTDATAFRAMELENGHT = this is input data frame lenght, number of rows in input data frame
# OUTPUTDATAFRAMELENGHT = this is output data frame lenght, number of rows in output data frame

# FILELINECOUNT =  this is  file line count, number of lines in file
# DATALINECOUNT = = number of line in output file excluding header and trailer, this number can differ from actual records in file if some data contains new line character
# FILENAME = Inside input or output file configuration, this will be replaced by current file name after processing placeholder but without base path
# FULLFILENAME = Inside input or output file configuration, this will be replaced by current file name after processing placeholder with base path
# FILENAMEWE = Inside input or output file configuration, this will be replaced by current file name after processing placeholder but without base path and extension
# EXPECTEDLINECOUNT = this is expected final count, sum of datalinecount and all the headers and trailers
# Define job name
name: first_job
group_seperator: "Â¶"
component_seperator: "â€¢"
ingnorable_character: 'ðŸ§¹'
child_access_symbol: 'â†’'

common_variables:
  test_varialbe: "test_value"
  test_varialbe1: "test_value2"


# Define job steps
job_steps:
  - step1:
      type: bcp_loader
      input_file:
        file_path: "/home/data/abc"
        file_prefix: "abasicfile_Â¶businessdateâ€¢floatâ€¢YYYY-MM-DDÂ¶"
        file_ext: ".csv"
        file_header_cnt: 3
        file_trailer_count: 2
        file_headers_in_order_to_validate:
          - "FILENAME=abasicfile_Â¶businessdateâ€¢dateâ€¢YYYY-MM-DDÂ¶ BUSINESS_DATE=Â¶BDATEâ€¢dateâ€¢YYYY-MM-DDÂ¶  CREATION_TIME=ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹"
          - 'col1,col2,col3,col4,col5'
        file_trailers_in_order_to_validate:
        - 'RECORDCOUNT=Â¶sourcefiledatacountâ€¢intâ€¢08dÂ¶'
      step_database: first_database1
      bcp_table: first_table1
      local_variable:
        test_varialbe1: "test_value"
  - step2:
      type: sql_executor
      sql_file_name: 'first_job.sql'
      step_database: first_database1 
  - step3:
      type: python_transformer
      local_variable:
        test_varialbe1: "test_value"
      function_name: 'first_job_transformer'
  - step4:
      type: sql_bcp_extractor
      sql_file_name: 'first_job1.sql'
      step_database: first_database1
      output_file:
        file_headers_in_order:
          - "FILENAME=abasicfile_Â¶businessdateâ€¢dateâ€¢YYYY-MM-DDÂ¶ BUSINESS_DATE=Â¶BDATEâ€¢dateâ€¢YYYY-MM-DDÂ¶  CREATION_TIME=ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹"
          - 'col1,col2,col3,col4,col5'
        file_trailers_in_order:
          - 'RECORDCOUNT=Â¶sourcefiledatacountâ€¢intâ€¢08dÂ¶'
        file_path: "/home/data/abc"
        file_prefix: "abasicfile_Â¶businessdateâ€¢floatâ€¢YYYY-MM-DDÂ¶"
        file_ext: ".csv"
  - step5:
      type: table_bcp_extractor
      table_name: 'Heavydev.dbo.product'
      step_database: remote
      validate: True
      output_file:
        delimiter: "|" #optional default is ','
        quote_char : 'ðŸ¤©ðŸ¤£'  #optional default is empty
        escape_char: '\'  #optional default is \, not used in bcp as of now, for future usey 
        path: "/home/deck/outbound"
        prefix: "FirstTestSample_Â¶BDATEâ€¢dateâ€¢YYYYMMDDÂ¶"
        ext: ".csv"
        headers_in_order:
          - "FILENAME=Â¶step5â†’output_fileâ†’FILENAMEâ€¢strâ€¢ <66Â¶ BATCH_DATE=Â¶BDATEâ€¢dateâ€¢YYYY-MM-DDÂ¶  CREATED_AT=Â¶CTIMEâ€¢dateâ€¢YYYY-MM-DDHH:mm:ssÂ¶"
          - 'AUTOPOPULATE'
          - 'xxxxxxxxxxxx'
        trailers_in_order:
          - 'RECORDCOUNT=Â¶step5â†’BCPPROCROWCNTâ€¢intâ€¢08dÂ¶'
          - 'LINECOUNT=Â¶step5â†’output_fileâ†’EXPECTEDLINECOUNTâ€¢intâ€¢08dÂ¶'
  - step6:
      type: sql_panda_extractor
      sql_file_name: 'first_job1.sql'
      step_database: first_database1
      output_file:
        file_headers_in_order:
          - "FILENAME=abasicfile_Â¶businessdateâ€¢dateâ€¢YYYY-MM-DDÂ¶ BUSINESS_DATE=Â¶BDATEâ€¢dateâ€¢YYYY-MM-DDÂ¶  CREATION_TIME=ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹"
          - 'col1,col2,col3,col4,col5'
        file_trailers_in_order:
          - 'RECORDCOUNT=Â¶sourcefiledatacountâ€¢intâ€¢08dÂ¶'
        file_path: "/home/data/abc"
        file_prefix: "abasicfile_Â¶businessdateâ€¢floatâ€¢YYYY-MM-DDÂ¶"
        file_ext: ".csv"
  - step7:
      type: table_panda_extractor
      table_name: 'first_job1'
      step_database: first_database1
      output_file:
        file_headers_in_order:
          - "FILENAME=abasicfile_Â¶businessdateâ€¢dateâ€¢YYYY-MM-DDÂ¶ BUSINESS_DATE=Â¶BDATEâ€¢dateâ€¢YYYY-MM-DDÂ¶  CREATION_TIME=ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹ðŸ§¹"
          - 'col1,col2,col3,col4,col5'
        file_trailers_in_order:
          - 'RECORDCOUNT=Â¶sourcefiledatacountâ€¢intâ€¢08dÂ¶'
        file_path: "/home/data/abc"
        file_prefix: "abasicfile_Â¶businessdateâ€¢floatâ€¢YYYY-MM-DDÂ¶"
        file_ext: ".csv"



